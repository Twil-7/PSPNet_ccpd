1、源码对应的是tensorflow1.6.0版本，在利用GPU训练，切换到tensorflow=2.4.1版本时，许多源码语法报错......

我修改了一些命令语句，最后将python3.6版本的PSPNet，成功过渡到了python3.8版本的PSPNet...

（1）in_channels = inputs.shape[-1].value，改成：in_channels = inputs.shape[-1]
（2）tf.image.resize_images，改成：tf.image.resize(x, (K.int_shape(y)[1], K.int_shape(y)[2]))


2、果然我天真了，才600多张图片，就想训练这种两百层的深度模型？？？可笑。
必须将前面的网络层完全冰冻起来！！！

37/37 [==============================] - 418s 11s/step - loss: 2.3027 - val_loss: 4.0724
Epoch 2/50
37/37 [==============================] - 407s 11s/step - loss: 1.2240 - val_loss: 4.9332
Epoch 3/50
37/37 [==============================] - 422s 11s/step - loss: 1.1339 - val_loss: 4.9864
Epoch 4/50
37/37 [==============================] - 429s 12s/step - loss: 1.0906 - val_loss: 4.5552
Epoch 5/50
37/37 [==============================] - 410s 11s/step - loss: 1.0477 - val_loss: 4.3906

训练效果真是一团垃圾......


3、将网络层冰冻起来后，虽然效果比之前好一些，val loss达到0.2左右，但调用它进行测试的时候，效果还是不够理想.......我觉得还是数据集太稀少了......

说句实话，几百张数据集训练语义分割的确不够，更何况这个数据集场景这么复杂，不是网络能轻易学会的...至少得上万张-十万张数据集吧...


4、我似乎找到了一个不错的开源数据集：

VOC12_AUG：是基于voc扩充的一个语义分割数据集。其组成可参考:https://blog.csdn.net/lscelory/article/details/98180917

地址： http://home.bharathh.info/pubs/codes/SBD/download.html

数据集比较大，单张图片中物体数量相对较少，场景和voc数据集的场景很像。
训练集10582，val：1449，类别也是继承自voc，共20个类别。


5、哦豁完蛋，11350张图形训练不出语义分割效果......难道还是应该把前面的mobilenet特征提取层冰冻起来？？？不过说实话，这个数据集是真的复杂，很难训练出效果......
这个数据集的图片内容是真的复杂，就算是同一个类别的内容，外形姿态也千奇百怪，我甚至怀疑，网络真的能够处理这种复杂情形吗......

Epoch 1/10
312/312 [==============================] - 4720s 15s/step - loss: 1.5729 - val_loss: 6.4392
Epoch 2/10
312/312 [==============================] - 4690s 15s/step - loss: 1.0811 - val_loss: 3.4715
Epoch 3/10
312/312 [==============================] - 4691s 15s/step - loss: 1.0853 - val_loss: 14.1515
Epoch 4/10
312/312 [==============================] - 4726s 15s/step - loss: 1.0838 - val_loss: 10.9031
Epoch 5/10
312/312 [==============================] - 4730s 15s/step - loss: 1.0439 - val_loss: 14.5418
Epoch 6/10
312/312 [==============================] - 4730s 15s/step - loss: 1.0416 - val_loss: 9.2228
Epoch 7/10
312/312 [==============================] - 4737s 15s/step - loss: 1.0455 - val_loss: 5.2644
Epoch 8/10
312/312 [==============================] - 4736s 15s/step - loss: 1.0594 - val_loss: 7.6098
Epoch 9/10
312/312 [==============================] - 4729s 15s/step - loss: 1.0583 - val_loss: 4.2101


6、我改用源代码中的训练方式，先将网络层冰冻起来，训练50次看看效果。我猜原作者居然能发这个链接，想必是真的能训练出一个良好结果的。


7、我重新把原作者代码中的数据集下载了下来，她的VOC2007数据集居然不一样，语义分割居然包含12031张图片，我基于此训练40轮，adam学习率取1e-4，看看到底能不能训练出效果。


8、11530张图片训练效果也不理想，val loss降低到0.2附近就完全瓶颈了，预测效果也很差劲。

Epoch 1/10
312/312 [==============================] - 1641s 5s/step - loss: 1.2581 - val_loss: 0.3743
Epoch 2/10
312/312 [==============================] - 2511s 8s/step - loss: 0.2494 - val_loss: 0.2592
Epoch 3/10
312/312 [==============================] - 2788s 9s/step - loss: 0.2080 - val_loss: 0.2238
Epoch 4/10
312/312 [==============================] - 2759s 9s/step - loss: 0.1871 - val_loss: 0.2170
Epoch 5/10
312/312 [==============================] - 2824s 9s/step - loss: 0.1769 - val_loss: 0.2152
Epoch 6/10
312/312 [==============================] - 2798s 9s/step - loss: 0.1690 - val_loss: 0.2137
Epoch 7/10
312/312 [==============================] - 2805s 9s/step - loss: 0.1623 - val_loss: 0.2117
Epoch 8/10
312/312 [==============================] - 2780s 9s/step - loss: 0.1526 - val_loss: 0.2148
Epoch 9/10
312/312 [==============================] - 2838s 9s/step - loss: 0.1511 - val_loss: 0.2100
Epoch 10/10
312/312 [==============================] - 2796s 9s/step - loss: 0.1476 - val_loss: 0.2138



9、又训练了一个晚上，训练结果依旧失望，可能真的是VOC数据集图片太过复杂，语义分割算法难以取得我想要的效果，无论怎么训练，val loss损失函数都只能降低到0.2附近。

为了验证PSPNet算法的有效性，我重新拿PSPNet去训练前面处理的ccpd-cropped数据集，看看有无效果。不过拿这100多层的mobilenet提取特征，有点高炮打蚊子的感觉......

目测这次效果还不错：

Epoch 1/10
187/187 [==============================] - 805s 4s/step - loss: 0.2659 - val_loss: 0.0573
Epoch 2/10
187/187 [==============================] - 711s 4s/step - loss: 0.0520 - val_loss: 0.0386
Epoch 3/10
187/187 [==============================] - 683s 4s/step - loss: 0.0409 - val_loss: 0.0311
Epoch 4/10
187/187 [==============================] - 690s 4s/step - loss: 0.0363 - val_loss: 0.0275
Epoch 5/10
187/187 [==============================] - 745s 4s/step - loss: 0.0346 - val_loss: 0.0251
Epoch 6/10
187/187 [==============================] - 745s 4s/step - loss: 0.0310 - val_loss: 0.0242
Epoch 7/10
187/187 [==============================] - 741s 4s/step - loss: 0.0291 - val_loss: 0.0252
Epoch 8/10
187/187 [==============================] - 753s 4s/step - loss: 0.0285 - val_loss: 0.0275
Epoch 9/10
187/187 [==============================] - 701s 4s/step - loss: 0.0269 - val_loss: 0.0223


10、拿训练好的PSPNet去检测ccpd-cropped图片，是什么狗屁效果，语义分割直接一塌糊涂，日了草。


11、我特么找了很久的bug，简直匪夷所思，明明训练出的结果val_accuracy这么高，怎么可能跑出来的结果这么差？！！！！！

最终我发现，是在权重导入出了问题，我原本写的是psp_model.load_weights('Logs/2/epoch055-loss0.050-val_loss0.223.h5', by_name=True, skip_mismatch=True)
这样训练好的一部分权重就直接他妈的被skip了，用的完全是随机初始化，自然预测出来稀烂！！！

而应该写成：psp_model.load_weights('Logs/2/epoch055-loss0.050-val_loss0.223.h5')，这样哪怕是VOC数据集，我语义分割的精度也能达到95%以上！！！完美！！！

这件事也让我联想到了以前训练时的一个bug，有时多轮训练，训练的val loss本来好好的，突然下一轮急剧跳高，仿佛白训练了一样，这不就是上次训练好的部分权重被skip了嘛......

Epoch 1/10
187/187 [==============================] - 364s 2s/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 0.0222 - val_accuracy: 0.9909
Epoch 2/10
187/187 [==============================] - 353s 2s/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 0.0214 - val_accuracy: 0.9911
Epoch 3/10
187/187 [==============================] - 361s 2s/step - loss: 0.0226 - accuracy: 0.9906 - val_loss: 0.0213 - val_accuracy: 0.9910


Epoch 1/10
187/187 [==============================] - 364s 2s/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 0.0222 - val_accuracy: 0.9909
Epoch 2/10
187/187 [==============================] - 353s 2s/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 0.0214 - val_accuracy: 0.9911
Epoch 3/10
187/187 [==============================] - 361s 2s/step - loss: 0.0226 - accuracy: 0.9906 - val_loss: 0.0213 - val_accuracy: 0.9910
Epoch 4/10
187/187 [==============================] - 351s 2s/step - loss: 0.0223 - accuracy: 0.9907 - val_loss: 0.0207 - val_accuracy: 0.9913
Epoch 5/10
187/187 [==============================] - 353s 2s/step - loss: 0.0216 - accuracy: 0.9910 - val_loss: 0.0210 - val_accuracy: 0.9911
Epoch 6/10
187/187 [==============================] - 365s 2s/step - loss: 0.0213 - accuracy: 0.9910 - val_loss: 0.0211 - val_accuracy: 0.9911
Epoch 7/10
187/187 [==============================] - 339s 2s/step - loss: 0.0209 - accuracy: 0.9912 - val_loss: 0.0206 - val_accuracy: 0.9914
Epoch 8/10
187/187 [==============================] - 339s 2s/step - loss: 0.0206 - accuracy: 0.9913 - val_loss: 0.0218 - val_accuracy: 0.9908
Epoch 9/10
187/187 [==============================] - 342s 2s/step - loss: 0.0205 - accuracy: 0.9914 - val_loss: 0.0214 - val_accuracy: 0.9910
Epoch 10/10
187/187 [==============================] - 355s 2s/step - loss: 0.0207 - accuracy: 0.9913 - val_loss: 0.0209 - val_accuracy: 0.9912



12、我特么连带着找到了faster rcnn那个bug问题，为什么我训练了那么久的权重，预测起来却一塌糊涂，他妈的不正是读取权重时skip了部分层数吗？！！！！

